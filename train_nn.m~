function [ w1, w2, test_err1, test_err2, train_err1, train_err2 ] = train_nn(obs, out, sizes_hidden, error_func)
%UNTITLED5 Summary of this function goes here
%   Detailed explanation goes here
    %load test set
    test_data = load('data/test.mat');
    test_images = create_sparse_img(double(test_data.test.images));
    test_images = [test_images ones(size(test_images,1), 1)];
    test_labels = double(test_data.test.labels); 
    test_err1 = [];
    test_err2 = [];
    train_err1 = [];
    train_err2 = [];
    if nargin < 3
        sizes_hidden = [];
    end
    og_step_size = .01;
    epsilon = .001;
    % add in bias term
    obs = [obs ones(size(obs,1),1)];
    num_in = size(obs,2);
    % 10 is the number of output classes
    num_out = 10;
    sizes = [num_in sizes_hidden num_out];
    w1 = {};
    w2 = {};
    for i = 1:length(sizes) - 1
        % center weights around 0
        w1{i} = rand(sizes(i), sizes(i+1)) - .5;
        w2{i} = w1{i};% rand(sizes(i), sizes(i+1)) * .001 - .0005;
    end
    num_batches = ceil(size(obs, 1) / 200);
    num_epochs = 100;
    for epoch = 1:num_epochs
        epoch
        % store error rates to plot
        if (epoch == 1 || mod(epoch,10) == 0)
            %test and training set error
            test_err1 = [test_err1 set_err(w1, test_images, test_labels)];
            test_err2 = [test_err2 set_err(w2, test_images, test_labels)];
            train_err1 = [train_err1 set_err(w1, obs, out)];
            train_err2 = [train_err2 set_err(w2, obs, out)];
        end
        % shuffle data
        p = randperm(size(obs, 1));
        rand_obs = reshape(obs(p,:), size(obs, 1), size(obs, 2));
        rand_out = reshape(out(p,:), size(out, 1), size(out, 2));
        step_size = (1.0 / (epoch ^ .5)) * og_step_size;
        % minibatch update
        for batch=1:num_batches
            % prepare data
            batch_size = min(200, size(rand_obs,1) - (batch - 1)*200);
            start = (batch - 1)*200 + 1;
            stop = start + batch_size - 1;
            data = rand_obs(start:stop,:); % batch_size x num_in
            labels = class_to_vector(rand_out(start:stop), num_out); % batch_size x num_out
            % make predictions and update for output layer
            predictions1 = make_predictions(w1, data);
            predictions2 = make_predictions(w2, data);
            % scale predictions for error calculation
            for layer=length(w1):-1:1
                scaled_predictions1{layer+1} = (predictions1{layer} + 1) ./ 2;
                scaled_predictions2{layer+1} = (predictions2{layer} + 1 
            end
            gradients1 = {};
            gradients2 = {};
            for layer=1:length(w1)
                gradients1{layer} = zeros(size(w1{layer}));
                gradients2{layer} = zeros(size(w2{layer})); 
            end
            for datum=1:batch_size
                for layer=length(w1):-1:1
                    % output layer
                    if layer == length(w1)
                    	delta1 = -(labels(datum,:) - predictions1{layer+1}(datum,:)) .* predictions1{layer+1}(datum,:) .* (1 - predictions1{layer+1}(datum,:)); % 1 x num_out
                        delta2 = ((1 - labels(datum,:)) ./ (1 - predictions2{layer+1}(datum,:) + epsilon) - labels(datum,:) ./ (predictions2{layer+1}(datum,:) + epsilon)) .*  predictions2{layer+1}(datum,:) .* (1 - predictions2{layer+1}(datum,:)); % 1 x num_out
                    % hidden layers
                    else
                        delta1 = (delta1 * w1{layer+1}') .* (1 - predictions1{layer+1}(datum,:) .^ 2);
                        delta2 = (delta2 * w2{layer+1}') .* (1 - predictions2{layer+1}(datum,:) .^ 2);
                    end
                    gradients1{layer} = gradients1{layer} + (predictions1{layer}(datum,:)' * delta1);
                    gradients2{layer} = gradients2{layer} + (predictions2{layer}(datum,:)' * delta2);
                end
            end
            for layer=1:length(w1)
                w1{layer} = w1{layer} - step_size * gradients1{layer};
                w2{layer} = w2{layer} - step_size * gradients2{layer};
            end
        end
    end
end

